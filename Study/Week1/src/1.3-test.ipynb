{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99dc393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface 处理大文件\n",
    "#1 数据加载\n",
    "## 1.1 加载本地数据\n",
    "## 1.2 分块加载本地大数据\n",
    "#2 token and embedding数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c8c843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b33c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\"train\": \"/home/ec2-user/project/AI/Study/Week1/data/train.csv\", \"validation\": \"/home/ec2-user/project/AI/Study/Week1/data/val.csv\"}\n",
    "down_dataset = load_dataset(\"csv\",data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62179c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prot_id', 'seq', 'seq_len', 'pdb_filename', 'ptm', 'mean_plddt', 'emb_filename', 'label', 'source'],\n",
       "        num_rows: 963\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['prot_id', 'seq', 'seq_len', 'pdb_filename', 'ptm', 'mean_plddt', 'emb_filename', 'label', 'source'],\n",
       "        num_rows: 275\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(down_dataset))\n",
    "down_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30c6968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataset_1 = load_dataset(\"csv\",data_files=data_files,\n",
    "    split=\"train\",\n",
    "    streaming=True,\n",
    "    cache_dir=\"../test/dataset\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b446b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: Unknown,\n",
       "    num_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_dataset\n",
    "#next(iter(big_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6cc4af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from triton==3.4.0->torch>=1.11.0->sentence-transformers) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/software/miniconda3/envs/week2/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f273e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token and embedding my big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c429bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import itertools\n",
    "from tqdm import tqdm  # 进度条，便于监控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "108a0551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必备库\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# ===================== 1. 基础配置（改这里的路径即可） =====================\n",
    "DATA_FILE = \"/home/ec2-user/project/AI/Study/Week1/data/train.csv\"  # 你的CSV文件\n",
    "SAVE_DIR = \"/home/ec2-user/project/AI/Study/Week1/test/dataset/embedding\"  # 保存embedding的文件夹\n",
    "CHUNK_SIZE = 64  # 每次处理64条数据（按需改）\n",
    "MODEL_NAME = \"facebook/esm2_t6_8M_UR50D\"  # ESM-2小模型\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 自动选GPU/CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "315bf966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载ESM-2模型...\n"
     ]
    }
   ],
   "source": [
    "# ===================== 2. 加载模型和分词器（一次性加载） =====================\n",
    "print(\"加载ESM-2模型...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).eval().to(DEVICE)  # 推理模式\n",
    "\n",
    "# 创建保存文件夹\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42dc0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "全部加载完成！共963条embedding\n",
      "[-0.007527138572186232, 0.5384337306022644, 0.1969233602285385, 0.3183571398258209, -0.022737350314855576, 0.04540286958217621, -0.47190532088279724, 0.0961337462067604, -0.24226747453212738, -0.8840938806533813, 0.32341644167900085, 0.24364060163497925, -0.813580334186554, -0.17932505905628204, -0.37175115942955017, -0.048180922865867615, 0.17804019153118134, -0.05104481428861618, -0.3904653787612915, -0.5403650403022766, -0.20769819617271423, -0.267784059047699, -0.34677940607070923, -0.0736531913280487, 0.16310368478298187, 0.3685562312602997, -0.40533530712127686, 0.10851006954908371, 0.18702229857444763, -0.06625205278396606, -0.001945540658198297, 0.0906536728143692, -0.35018134117126465, 0.17474716901779175, 0.13165134191513062, -0.16855557262897491, -0.18857955932617188, -0.32526490092277527, 0.1622246354818344, -0.4267810881137848, 0.21074829995632172, 0.011185672134160995, -0.3855058252811432, -0.12766128778457642, 0.294915109872818, 0.46019843220710754, 0.6746958494186401, 0.036475591361522675, 0.03772667795419693, 0.2880580723285675, 0.39249345660209656, -0.26127031445503235, 0.17984218895435333, -0.3021996319293976, -0.04884452000260353, 0.685150146484375, 0.03258596733212471, -0.4456077516078949, 0.27613043785095215, 0.12797075510025024, -0.5331421494483948, -0.1718052178621292, -3.993051528930664, 0.052661772817373276, -0.5256301760673523, -0.20503157377243042, -0.8339873552322388, 0.41163772344589233, -0.08734286576509476, 0.4569378197193146, 0.46341946721076965, -0.242791086435318, 0.048331368714571, 0.5961961150169373, -0.05138375982642174, -0.696431040763855, 0.3016384541988373, -0.2063017636537552, 0.21953734755516052, 0.46697503328323364, 0.3346325755119324, 0.009486173279583454, 0.43301424384117126, 0.3745514154434204, 0.03958543762564659, -0.22219611704349518, 0.034297484904527664, 0.43692725896835327, 0.5703480839729309, -0.31152865290641785, 0.10613591223955154, -0.07459928095340729, -0.5865979194641113, 0.30706787109375, -0.1364298015832901, 0.34941545128822327, -0.3957327604293823, -0.27840131521224976, 0.4289385676383972, 0.17571765184402466, 0.46033617854118347, 0.13633574545383453, -0.4918830394744873, -0.4550006091594696, -0.03861534222960472, -0.17095917463302612, 0.4885686933994293, -0.6720995903015137, -0.3021058440208435, -0.014486007392406464, -0.04450139403343201, -0.24852776527404785, 0.6133500933647156, -0.22117137908935547, 0.047097135335206985, 0.279789537191391, -0.2408973127603531, -0.2586769759654999, 0.1413985639810562, 0.04094905033707619, -0.5041714310646057, -0.27119579911231995, -0.23109623789787292, 0.019313091412186623, 0.3260030150413513, -0.09260674566030502, -0.16923663020133972, 0.06333014369010925, 0.1934039294719696, -0.01400002557784319, 0.5592325925827026, -0.46948692202568054, 0.034774526953697205, 0.14233647286891937, -0.02873600646853447, 0.21362707018852234, 0.48504817485809326, -0.2038487046957016, -0.3001330494880676, 0.07855542749166489, 0.1859624832868576, 0.11178673058748245, -0.346066951751709, 0.3258252441883087, 0.06348317861557007, 0.4398469626903534, 0.2183147519826889, -0.256110817193985, -0.6183571815490723, -0.10192941874265671, -0.9555665254592896, 0.4483886957168579, -0.003407575422897935, -0.21183347702026367, 0.11330187320709229, -0.7329630851745605, 0.06416133046150208, 0.46956297755241394, 0.31698286533355713, 0.47178617119789124, 0.3978208601474762, 0.0050780437886714935, -0.913141667842865, 0.028714368119835854, -0.14239810407161713, 0.4911056458950043, 0.2387174665927887, -0.07268641889095306, -0.06259996443986893, -0.048673905432224274, -0.3631928563117981, 0.6130390763282776, 0.321120023727417, -0.15551845729351044, 0.03737764433026314, -0.5929401516914368, 0.41237297654151917, 0.16274364292621613, 0.4290791153907776, -0.25515440106391907, 0.2966043949127197, 0.002479349263012409, -0.43041861057281494, 4.1216553654521704e-05, -0.23816156387329102, 0.022851958870887756, 0.2195904552936554, 0.09571900218725204, -0.09357443451881409, 8.342367073055357e-05, -0.3058697581291199, 0.6925249695777893, 0.5862498879432678, -0.15953637659549713, 0.14520010352134705, 0.6370289325714111, -0.25707074999809265, -0.11497851461172104, -0.0938577800989151, 0.030920401215553284, 0.28714999556541443, -0.06364046037197113, -0.18037185072898865, -0.023210858926177025, -0.3440447151660919, 0.25036391615867615, 0.4758756160736084, 0.026646509766578674, -0.21010389924049377, -0.3840946853160858, 0.002331735100597143, -0.19060735404491425, 0.6106863617897034, 0.19919642806053162, -0.4024364650249481, -0.011996287852525711, -0.1375720500946045, -0.26587021350860596, -0.03544442355632782, -0.4625151753425598, 0.30796298384666443, -0.1598736196756363, -0.31008780002593994, 0.20278781652450562, 0.016032399609684944, -0.0488746203482151, -0.3284858763217926, 0.04464904963970184, 0.19911609590053558, -0.04842670261859894, 0.58709716796875, -0.2800968885421753, 0.029557012021541595, 0.16251100599765778, 0.2405996322631836, 0.1067071408033371, 0.3354092836380005, -0.4594689607620239, 0.36784112453460693, 0.38732144236564636, -0.4629143476486206, 0.2181531935930252, 0.03005076013505459, 0.14091046154499054, 0.614926278591156, -0.3353310227394104, 0.23097673058509827, 0.18173643946647644, 0.09135854244232178, 0.08877544850111008, -0.34123432636260986, -0.030507994815707207, -0.3924674391746521, -0.0407877191901207, -0.24409008026123047, -0.6219528317451477, -0.07136543840169907, -0.1313168704509735, 0.5623035430908203, -0.48545020818710327, -0.09145022183656693, -0.7957063913345337, 0.4506511092185974, 0.558272659778595, 0.1946256309747696, -0.6216193437576294, -0.01676180213689804, 0.010102740488946438, 0.05694292485713959, 0.23801055550575256, -0.10817161947488785, 0.7157632112503052, 0.27520889043807983, -0.21201156079769135, -0.03759163245558739, -0.29985299706459045, -0.3414406478404999, -0.14094987511634827, -0.0706690102815628, 0.49440041184425354, 0.4838475286960602, -0.11657924950122833, -0.175723597407341, -0.3895575702190399, -0.2053156942129135, -0.2688041627407074, -1.018142580986023, 0.4769670367240906, 0.1395556479692459, -0.3785673975944519, 0.16688768565654755, -0.07422485202550888, 0.15010780096054077, -0.19348135590553284, 0.0936616063117981, -0.1558561474084854, 0.13662320375442505, -0.6612327098846436, 0.5916114449501038, 0.5350936651229858, 0.5118651390075684, -0.16013555228710175, -0.23453353345394135, 0.2760204076766968, 0.4218868911266327, 0.30776798725128174, -0.21758362650871277, -0.3748871088027954, 0.0017572266515344381, 0.0486484132707119, -0.41199928522109985, -0.027999114245176315, 1.0382146835327148, -0.03643982484936714, 0.5084158182144165, 0.13556833565235138, 0.29119357466697693, 0.7787798643112183, -0.19117556512355804, -0.27470269799232483]\n"
     ]
    }
   ],
   "source": [
    "# ===================== 3. 流式读取数据+计算embedding =====================\n",
    "# 加载CSV为流式数据集（不占内存）\n",
    "dataset = load_dataset(\"csv\", data_files=DATA_FILE, split=\"train\", streaming=True)\n",
    "dataset_iter = iter(dataset)  # 转为迭代器。举例子：next(dataset_iter) 即可取一条数据\n",
    "chunk_idx = 0 # 块索引\n",
    "# 逐块处理数据\n",
    "while True: \n",
    "    # 1 这是把数据以64条为一块取出来 2是进行序列处理\n",
    "    batch_data =[] # batch_data 存储64块数据\n",
    "    for _ in range(CHUNK_SIZE):\n",
    "        try:\n",
    "            item = next(dataset_iter)\n",
    "            batch_data.append(item)\n",
    "        except StopIteration:\n",
    "            break\n",
    "    if not batch_data:\n",
    "        break  # 数据取完，退出循环\n",
    "\n",
    "    # 2. 提取序列和ID，过滤空值。 用来保存为 embedding\n",
    "    seqs = [item[\"seq\"] for item in batch_data if item[\"seq\"]] # 列表表达式提取序列\n",
    "    prot_ids = [item[\"prot_id\"] for item in batch_data if item[\"seq\"]]\n",
    "    if not seqs:\n",
    "        chunk_idx +=1\n",
    "        continue\n",
    "\n",
    "    # 3 分词+计算embedding\n",
    "    inputs = tokenizer(seqs, return_tensors='pt', padding=True, truncation=True, max_length=1024).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:,0,:].cpu().numpy()\n",
    "\n",
    "    # 4. 保存结果（JSON格式，ID和embedding一一对应）\n",
    "    emb_dict = {pid: emb.tolist() for pid, emb in zip(prot_ids, embeddings)}\n",
    "    json_path = os.path.join(SAVE_DIR, f\"emb_chunk_{chunk_idx}.json\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(emb_dict, f)\n",
    "    \n",
    "    #print(f\"第{chunk_idx}块：保存{len(emb_dict)}条embedding\")\n",
    "    chunk_idx += 1\n",
    "\n",
    "\n",
    "def load_all_embeddings(save_dir):\n",
    "    \"\"\"加载所有保存的embedding，返回{prot_id: embedding}的字典\"\"\"\n",
    "    all_emb = {}\n",
    "    for file in os.listdir(save_dir):\n",
    "        if file.startswith(\"emb_chunk_\") and file.endswith(\".json\"):\n",
    "            with open(os.path.join(save_dir, file), \"r\") as f:\n",
    "                all_emb.update(json.load(f))\n",
    "    return all_emb\n",
    "all_emb = load_all_embeddings(SAVE_DIR)\n",
    "print(f\"\\n全部加载完成！共{len(all_emb)}条embedding\")\n",
    "print(all_emb[\"REP|ywg_BAD18935.1\"]) #一维矩阵，长320"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
